{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1 - Question and Answers\n",
    "In this workshop, you will learning how to write prompts and feed them into LLMs. You\n",
    "will also be learning how to use different prompt techniques to improve the response\n",
    "from the LLM.\n",
    "\n",
    "## Loading and Explorng the Dataset\n",
    "The workshop will be using [`facebook/ExploreToM`](https://huggingface.co/datasets/facebook/ExploreToM) dataset from [HuggingFace](https://huggingface.co)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the following libraries: datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset name\n",
    "dataset_name = \"facebook/ExploreToM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load dataset\n",
    "ds = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (13309, 18)}\n",
      "dict_keys(['train'])\n",
      "{'story_structure': Value('string'), 'infilled_story': Value('string'), 'question': Value('string'), 'expected_answer': Value('string'), 'qprop=params': Value('string'), 'qprop=nth_order': Value('int64'), 'qprop=non_unique_mental_state': Value('bool'), 'sprop=is_false_belief_story_1st': Value('bool'), 'sprop=is_false_belief_story_1st_and_2nd': Value('bool'), 'sprop=story_accuracy_1st_raw': Value('float64'), 'sprop=story_accuracy_1st_infilled': Value('float64'), 'sprop=global_idx': Value('int64'), 'param=story_type': Value('string'), 'param=num_stories_total': Value('int64'), 'param=max_sentences': Value('int64'), 'param=num_people': Value('int64'), 'param=num_moves': Value('int64'), 'param=num_rooms': Value('int64')}\n",
      "key: story_structure\n",
      "\tMia entered the hospital staff lounge. Amelia entered the hospital staff lounge. Mia told privately to Madison about the hospital budget cuts. Madison entered the hospital staff lounge. Madison told privately to Mia about the accreditation requirements. Jasmine entered the hospital staff lounge. Jasmine told privately to Amelia about the accreditation requirements.\n",
      "key: infilled_story\n",
      "\tThe hospital staff lounge, a small oasis amidst the bustling hospital corridors, was filled with the aroma of stale coffee and the soft hum of the refrigerator. The lounge's worn furniture and faded walls seemed to bear witness to countless conversations and late-night shifts, a backdrop for moments of rest and refuge. Mia slipped into the hospital staff lounge, her eyes scanning the room for a glimpse of the latest hospital bulletin, and Amelia followed closely, her worn shoes quiet on the scuffed linoleum floor. Mia discreetly tugged Madison into a private conversation, the topic of their hushed discussion immediately evident in the looks exchanged between them - concerned expressions that contrasted with the humdrum atmosphere of the staff lounge. The hospital staff lounge's scuffed linoleum floor creaked softly as Madison entered, her gaze drifting towards the usual gathering spots where colleagues shared stories and advice. A flutter of concern danced across Mia's face as Madison confided the details of the looming accreditation requirements, each phrase spilling into the next in a low, urgent cadence. The worn walls of the hospital staff lounge seemed to fade, leaving only the space between them, charged with an unspoken sense of uncertainty. Jasmine's confident stride echoed through the staff lounge as she made her entrance, her eyes swiftly scanning the room. A silent understanding flashed between Jasmine and Amelia as they moved into a corner of the lounge, far enough away from the other hospital staff to converse discreetly; it was here that Jasmine chose to brief Amelia on the nitty-gritty of the accreditation process, offering reassurances as much as concrete facts.\n",
      "key: question\n",
      "\tWhat does Madison think about Amelia's belief on accreditation requirements? (knows about it / does not know about it)\n",
      "key: expected_answer\n",
      "\tdoes not know about it\n",
      "key: qprop=params\n",
      "\t(['Madison', 'Amelia'], 'accreditation requirements', '<knowledge>-False')\n",
      "key: qprop=nth_order\n",
      "\t2\n",
      "key: qprop=non_unique_mental_state\n",
      "\tTrue\n",
      "key: sprop=is_false_belief_story_1st\n",
      "\tTrue\n",
      "key: sprop=is_false_belief_story_1st_and_2nd\n",
      "\tTrue\n",
      "key: sprop=story_accuracy_1st_raw\n",
      "\t0.875\n",
      "key: sprop=story_accuracy_1st_infilled\n",
      "\t0.5\n",
      "key: sprop=global_idx\n",
      "\t274\n",
      "key: param=story_type\n",
      "\tfantom-private\n",
      "key: param=num_stories_total\n",
      "\t10\n",
      "key: param=max_sentences\n",
      "\t15\n",
      "key: param=num_people\n",
      "\t4\n",
      "key: param=num_moves\n",
      "\t3\n",
      "key: param=num_rooms\n",
      "\t1\n"
     ]
    }
   ],
   "source": [
    "# TODO: number of rows in the dataset\n",
    "print(ds.shape)\n",
    "\n",
    "# TODO: Keys in the dataset\n",
    "print(ds.keys())\n",
    "\n",
    "# TODO: Feature names\n",
    "print(ds['train'].features)\n",
    "\n",
    "# TODO: Display a single row\n",
    "idx = 5000\n",
    "for k, v in ds['train'][idx].items():\n",
    "   print(f'key: {k}\\n\\t{v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pipeline`\n",
    "[`pipeline`](https://huggingface.co/docs/transformers/en/main_classes/pipelines) is an easy to use API to perform inferencing. It provides a wrapper for task-specific pipelines and abstracts most of the complexity by allowing you to focus on the model and the task. \n",
    "\n",
    "You can use `pipeline` to perform summarisation, image classification, audio generation, etc. You can find an exhaustive list of `pipeline` task [here](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.pipeline.task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "qna = pipeline('question-answering', model=\"distilbert/distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: {'score': 0.26706773042678833, 'start': 633, 'end': 656, 'answer': 'the ornate wooden chest'}\n",
      "actual: wooden chest\n"
     ]
    }
   ],
   "source": [
    "# TODO: Summarise the text with the pipeline's default model\n",
    "idx = 10\n",
    "q = ds['train'][idx]['question']\n",
    "story = ds['train'][idx]['story_structure']\n",
    "story = ds['train'][idx]['infilled_story']\n",
    "a = ds['train'][idx]['expected_answer']\n",
    "\n",
    "predicted_ans = qna(question=q, context=story)\n",
    "\n",
    "print(f'predicted: {predicted_ans}')\n",
    "print(f'actual: {a}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Inference - Question and Answer\n",
    "In this section, we will look at what `pipeline` does under the hood to perform its inference. This will give us a better understanding of the major steps involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load tokenizer\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT base cased distilled SQuAD\n",
    "DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. More details [here](https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-cased-distilled-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "          1176,  1757,  1104,  1103,  1769,  1713,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "          1176,  1757,  1104,  1103,  1769,  1713,   119,   102]])\n",
      "18\n",
      "[CLS] Thou shall not create a machine in the likeness of the human mind. [SEP]\n",
      "101 = [CLS]\n",
      "157 = T\n",
      "14640 = ##hou\n",
      "4103 = shall\n",
      "1136 = not\n",
      "2561 = create\n",
      "170 = a\n",
      "3395 = machine\n",
      "1107 = in\n",
      "1103 = the\n",
      "1176 = like\n",
      "1757 = ##ness\n",
      "1104 = of\n",
      "1103 = the\n",
      "1769 = human\n",
      "1713 = mind\n",
      "119 = .\n",
      "102 = [SEP]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Encode text\n",
    "text = \"Thou shall not create a machine in the likeness of the human mind.\"\n",
    "\n",
    "enc_text = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(enc_text)\n",
    "\n",
    "input_ids = enc_text.input_ids\n",
    "\n",
    "print(input_ids)\n",
    "print(len(input_ids[0]))\n",
    "\n",
    "dec_text = tokenizer.decode(input_ids[0])\n",
    "print(dec_text)\n",
    "\n",
    "for i in input_ids[0]:\n",
    "   print(f'{i} = {tokenizer.decode(i)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "          1176,  1757,  1104,  1103,  1769,  1713,   119,   102],\n",
      "        [  101,  2562,  1602, 15430, 24752,  1116,  1602,  1892,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Encoding multiple texts\n",
    "text0 = \"Thou shall not create a machine in the likeness of the human mind.\"\n",
    "text1 = \"Big black bug bleeds black blood\"\n",
    "texts = [ text0, text1 ]\n",
    "\n",
    "enc_texts = tokenizer(texts, return_tensors='pt', padding=True)\n",
    "print(enc_texts)\n",
    "print(enc_texts.attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thou shall not create a machine in the likeness of the human mind.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Decode text\n",
    "dec_text = tokenizer.decode(enc_texts.input_ids[0], skip_special_tokens=True)\n",
    "print(dec_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with LLMs\n",
    "Create and instance of the Large Language Model (LLM). We will then create a simple\n",
    "prompt, tokenize the prompt and feed the tokenized prompt to the LLM. The response\n",
    "from the LLM will be decoded to human friendly text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load libraries\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load question answer model\n",
    "idx = 20\n",
    "question = ds['train'][idx]['question']\n",
    "story = ds['train'][idx]['story_structure']\n",
    "story = ds['train'][idx]['infilled_story']\n",
    "answer = ds['train'][idx]['expected_answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode context and question\n",
    "enc_question = tokenizer(question, return_tensors='pt')\n",
    "enc_story = tokenizer(story, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-1.6762, -5.5590, -5.2944, -5.5207, -7.1013, -6.8303, -6.1847, -6.7702,\n",
      "         -6.2648, -6.2650, -4.8729, -6.9568, -5.4893, -5.7987, -7.9971, -6.9057,\n",
      "         -6.8193, -8.1302, -7.2304, -7.7575, -6.5525, -7.1091, -7.9345, -6.2591,\n",
      "         -5.6751, -8.1623, -5.5561, -5.4626, -2.3985, -2.1461, -1.6427, -4.7434,\n",
      "         -5.2374, -4.6589, -5.0070, -7.5811, -2.9745, -4.3427, -7.5754, -1.4883,\n",
      "         -6.6185, -6.5478, -6.1802, -7.7331, -7.8525, -4.6266, -5.8283, -6.6032,\n",
      "         -6.3370, -5.9505, -4.3827, -4.8499, -7.7499, -6.2904, -8.6796, -6.8582,\n",
      "         -5.7991, -5.7373, -8.4358, -4.9082, -6.3032, -8.7109, -5.5836, -4.8491,\n",
      "         -6.4376, -3.3497, -4.8125, -6.8941, -8.4276, -6.2874, -7.3141, -6.9046,\n",
      "         -2.8717, -7.1186, -7.5646, -6.8215, -6.8792, -7.7840, -6.2740, -6.8292,\n",
      "         -6.4743, -5.6433, -4.2358, -4.7700, -6.5172, -7.7997, -6.9551, -5.5443,\n",
      "         -7.4789, -8.0116, -3.3503, -8.5924, -7.1861, -6.6761, -6.3505, -8.2982,\n",
      "         -6.2836, -6.8474, -7.1803, -7.4104, -6.0943, -6.0417, -7.9994, -7.5586,\n",
      "         -5.7496, -7.1249, -5.9383, -3.0908, -6.4576, -8.2035, -5.2706, -5.6527,\n",
      "         -7.3133, -5.6996, -0.7560, -5.9950, -7.5110, -5.0386, -5.7883, -6.1349,\n",
      "         -7.9151, -6.6240, -5.8517, -5.5492, -6.2229, -7.1662, -5.3110, -5.3064,\n",
      "         -3.3307, -7.1336, -7.3797, -4.5731, -4.0991, -5.2245, -6.3252, -4.7370,\n",
      "         -4.5293, -2.2944, -2.6426, -0.3633,  5.0022,  7.4508, -0.0343, -5.5905,\n",
      "         -6.1058, -6.0396, -5.7058, -5.5150, -6.0869, -5.3805, -6.8297, -5.9183,\n",
      "         -4.8128, -6.0989, -6.3317, -5.9158, -3.7724, -5.0165, -6.0900, -6.6771,\n",
      "         -6.6651, -3.0796, -6.3740, -7.7833, -7.0456, -6.4946, -4.5788, -4.1712,\n",
      "         -4.7464, -8.2027, -4.4212, -8.6367, -5.5578, -7.0416, -5.0883, -5.3772,\n",
      "         -7.3251, -7.6863, -7.5045, -3.0931, -3.5274, -2.6694,  2.7493,  4.6770,\n",
      "         -1.7828, -8.1754, -5.7197, -7.7605, -6.5617, -6.7231, -6.5513, -5.5991,\n",
      "         -1.4587, -0.8800, -0.1422, -3.7369, -5.1830, -7.1132, -5.6968, -7.3156,\n",
      "         -6.2156, -5.6425, -6.4708, -6.4041, -3.7652, -3.2328, -6.3351, -6.7836,\n",
      "         -5.7912, -6.5087, -7.0693, -6.3621, -6.9467, -8.2619, -7.3684, -8.3046,\n",
      "         -6.0287, -7.6065, -5.4622, -6.2048, -6.7468, -6.6520, -7.0556, -8.4841,\n",
      "         -5.5351, -5.2079, -4.8088, -7.5599, -6.9567]],\n",
      "       grad_fn=<CloneBackward0>), end_logits=tensor([[-0.8658, -7.0310, -6.2526, -5.3428, -7.5510, -8.7126, -6.4966, -8.0193,\n",
      "         -7.5912, -5.9521, -5.4503, -7.6205, -7.5407, -5.6710, -8.2826, -7.4653,\n",
      "         -5.4119, -6.3703, -8.5876, -8.5981, -7.3070, -6.1530, -8.3136, -7.5881,\n",
      "         -7.1546, -6.9363, -4.3366, -5.2593, -6.8421, -6.5270, -4.8017, -0.9303,\n",
      "         -3.0955, -7.8995, -5.7113, -8.3829, -4.5770, -3.7559, -5.9254, -2.3636,\n",
      "         -7.2926, -6.2009, -2.7759, -4.8013, -7.9075, -5.8828, -6.1470, -3.2770,\n",
      "         -6.7872, -7.0275, -5.0795, -2.4589, -4.3129, -6.9996, -7.9959, -7.7315,\n",
      "         -6.8849, -5.7104, -8.3945, -6.8944, -4.0146, -8.3364, -6.5509, -2.6352,\n",
      "         -4.1454, -6.9414, -4.6247, -8.1673, -7.2960, -4.0619, -4.1987, -7.5413,\n",
      "         -7.0641, -6.6929, -3.5983, -6.8168, -4.9703, -4.4463, -7.5597, -6.7016,\n",
      "         -7.3629, -7.4355, -5.5350, -5.9697, -2.5280, -4.2291, -6.7387, -7.4425,\n",
      "         -5.8779, -6.8937, -3.7385, -7.4623, -7.5047, -7.2851, -3.7393, -5.5035,\n",
      "         -7.4359, -6.7666, -7.2427, -7.7327, -7.6488, -5.5184, -7.4759, -6.8230,\n",
      "         -4.2708, -4.7206, -7.3450, -3.7149, -7.1824, -7.6397, -6.4178, -6.3545,\n",
      "         -6.3468, -7.0116, -0.9107, -3.2007, -4.4342, -6.5775, -6.1716, -7.2139,\n",
      "         -5.8282, -7.3349, -7.0202, -6.0662, -3.2688, -3.7461, -6.5166, -7.0844,\n",
      "         -7.1468, -6.9052, -4.1258, -6.9784, -5.1218, -3.3924, -6.7430, -5.7581,\n",
      "         -4.8593, -5.9569, -1.8554, -4.6880, -2.9531,  5.7707,  7.6155,  0.8534,\n",
      "         -6.5978, -7.4820, -7.2165, -6.9914, -5.6476, -3.5741, -6.7033, -6.1090,\n",
      "         -5.3137, -6.0461, -2.1894, -2.0088, -7.6485, -6.7627, -6.7280, -4.3589,\n",
      "         -4.8020, -4.1063, -7.5934, -6.0801, -5.7073, -6.7106, -6.8266, -5.2361,\n",
      "         -4.4704, -7.6308, -4.4066, -8.0449, -2.4303, -2.7846, -6.5225, -7.4112,\n",
      "         -7.6875, -6.2523, -5.8797, -6.8610, -3.4390, -6.4846, -4.0963,  2.6750,\n",
      "          4.9457, -6.2610, -7.6940, -6.4926, -7.0780, -4.6668, -4.5269, -6.0952,\n",
      "         -5.9095, -4.0563, -0.8159, -5.5146,  0.4706, -2.0994, -6.0586, -7.2269,\n",
      "         -7.5140, -6.6654, -3.8421, -7.5243, -6.5984, -5.5367, -0.8246, -2.5889,\n",
      "         -7.3133, -6.7340, -7.9594, -7.2898, -6.5269, -8.3374, -4.6605, -5.4482,\n",
      "         -7.3946, -8.2005, -7.9628, -6.0347, -7.7938, -7.7111, -6.3044, -7.8707,\n",
      "         -8.0622, -6.1028, -3.2196, -3.6361, -7.6203]],\n",
      "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n",
      "tensor([[-1.6762, -5.5590, -5.2944, -5.5207, -7.1013, -6.8303, -6.1847, -6.7702,\n",
      "         -6.2648, -6.2650, -4.8729, -6.9568, -5.4893, -5.7987, -7.9971, -6.9057,\n",
      "         -6.8193, -8.1302, -7.2304, -7.7575, -6.5525, -7.1091, -7.9345, -6.2591,\n",
      "         -5.6751, -8.1623, -5.5561, -5.4626, -2.3985, -2.1461, -1.6427, -4.7434,\n",
      "         -5.2374, -4.6589, -5.0070, -7.5811, -2.9745, -4.3427, -7.5754, -1.4883,\n",
      "         -6.6185, -6.5478, -6.1802, -7.7331, -7.8525, -4.6266, -5.8283, -6.6032,\n",
      "         -6.3370, -5.9505, -4.3827, -4.8499, -7.7499, -6.2904, -8.6796, -6.8582,\n",
      "         -5.7991, -5.7373, -8.4358, -4.9082, -6.3032, -8.7109, -5.5836, -4.8491,\n",
      "         -6.4376, -3.3497, -4.8125, -6.8941, -8.4276, -6.2874, -7.3141, -6.9046,\n",
      "         -2.8717, -7.1186, -7.5646, -6.8215, -6.8792, -7.7840, -6.2740, -6.8292,\n",
      "         -6.4743, -5.6433, -4.2358, -4.7700, -6.5172, -7.7997, -6.9551, -5.5443,\n",
      "         -7.4789, -8.0116, -3.3503, -8.5924, -7.1861, -6.6761, -6.3505, -8.2982,\n",
      "         -6.2836, -6.8474, -7.1803, -7.4104, -6.0943, -6.0417, -7.9994, -7.5586,\n",
      "         -5.7496, -7.1249, -5.9383, -3.0908, -6.4576, -8.2035, -5.2706, -5.6527,\n",
      "         -7.3133, -5.6996, -0.7560, -5.9950, -7.5110, -5.0386, -5.7883, -6.1349,\n",
      "         -7.9151, -6.6240, -5.8517, -5.5492, -6.2229, -7.1662, -5.3110, -5.3064,\n",
      "         -3.3307, -7.1336, -7.3797, -4.5731, -4.0991, -5.2245, -6.3252, -4.7370,\n",
      "         -4.5293, -2.2944, -2.6426, -0.3633,  5.0022,  7.4508, -0.0343, -5.5905,\n",
      "         -6.1058, -6.0396, -5.7058, -5.5150, -6.0869, -5.3805, -6.8297, -5.9183,\n",
      "         -4.8128, -6.0989, -6.3317, -5.9158, -3.7724, -5.0165, -6.0900, -6.6771,\n",
      "         -6.6651, -3.0796, -6.3740, -7.7833, -7.0456, -6.4946, -4.5788, -4.1712,\n",
      "         -4.7464, -8.2027, -4.4212, -8.6367, -5.5578, -7.0416, -5.0883, -5.3772,\n",
      "         -7.3251, -7.6863, -7.5045, -3.0931, -3.5274, -2.6694,  2.7493,  4.6770,\n",
      "         -1.7828, -8.1754, -5.7197, -7.7605, -6.5617, -6.7231, -6.5513, -5.5991,\n",
      "         -1.4587, -0.8800, -0.1422, -3.7369, -5.1830, -7.1132, -5.6968, -7.3156,\n",
      "         -6.2156, -5.6425, -6.4708, -6.4041, -3.7652, -3.2328, -6.3351, -6.7836,\n",
      "         -5.7912, -6.5087, -7.0693, -6.3621, -6.9467, -8.2619, -7.3684, -8.3046,\n",
      "         -6.0287, -7.6065, -5.4622, -6.2048, -6.7468, -6.6520, -7.0556, -8.4841,\n",
      "         -5.5351, -5.2079, -4.8088, -7.5599, -6.9567]],\n",
      "       grad_fn=<CloneBackward0>)\n",
      "tensor([[-0.8658, -7.0310, -6.2526, -5.3428, -7.5510, -8.7126, -6.4966, -8.0193,\n",
      "         -7.5912, -5.9521, -5.4503, -7.6205, -7.5407, -5.6710, -8.2826, -7.4653,\n",
      "         -5.4119, -6.3703, -8.5876, -8.5981, -7.3070, -6.1530, -8.3136, -7.5881,\n",
      "         -7.1546, -6.9363, -4.3366, -5.2593, -6.8421, -6.5270, -4.8017, -0.9303,\n",
      "         -3.0955, -7.8995, -5.7113, -8.3829, -4.5770, -3.7559, -5.9254, -2.3636,\n",
      "         -7.2926, -6.2009, -2.7759, -4.8013, -7.9075, -5.8828, -6.1470, -3.2770,\n",
      "         -6.7872, -7.0275, -5.0795, -2.4589, -4.3129, -6.9996, -7.9959, -7.7315,\n",
      "         -6.8849, -5.7104, -8.3945, -6.8944, -4.0146, -8.3364, -6.5509, -2.6352,\n",
      "         -4.1454, -6.9414, -4.6247, -8.1673, -7.2960, -4.0619, -4.1987, -7.5413,\n",
      "         -7.0641, -6.6929, -3.5983, -6.8168, -4.9703, -4.4463, -7.5597, -6.7016,\n",
      "         -7.3629, -7.4355, -5.5350, -5.9697, -2.5280, -4.2291, -6.7387, -7.4425,\n",
      "         -5.8779, -6.8937, -3.7385, -7.4623, -7.5047, -7.2851, -3.7393, -5.5035,\n",
      "         -7.4359, -6.7666, -7.2427, -7.7327, -7.6488, -5.5184, -7.4759, -6.8230,\n",
      "         -4.2708, -4.7206, -7.3450, -3.7149, -7.1824, -7.6397, -6.4178, -6.3545,\n",
      "         -6.3468, -7.0116, -0.9107, -3.2007, -4.4342, -6.5775, -6.1716, -7.2139,\n",
      "         -5.8282, -7.3349, -7.0202, -6.0662, -3.2688, -3.7461, -6.5166, -7.0844,\n",
      "         -7.1468, -6.9052, -4.1258, -6.9784, -5.1218, -3.3924, -6.7430, -5.7581,\n",
      "         -4.8593, -5.9569, -1.8554, -4.6880, -2.9531,  5.7707,  7.6155,  0.8534,\n",
      "         -6.5978, -7.4820, -7.2165, -6.9914, -5.6476, -3.5741, -6.7033, -6.1090,\n",
      "         -5.3137, -6.0461, -2.1894, -2.0088, -7.6485, -6.7627, -6.7280, -4.3589,\n",
      "         -4.8020, -4.1063, -7.5934, -6.0801, -5.7073, -6.7106, -6.8266, -5.2361,\n",
      "         -4.4704, -7.6308, -4.4066, -8.0449, -2.4303, -2.7846, -6.5225, -7.4112,\n",
      "         -7.6875, -6.2523, -5.8797, -6.8610, -3.4390, -6.4846, -4.0963,  2.6750,\n",
      "          4.9457, -6.2610, -7.6940, -6.4926, -7.0780, -4.6668, -4.5269, -6.0952,\n",
      "         -5.9095, -4.0563, -0.8159, -5.5146,  0.4706, -2.0994, -6.0586, -7.2269,\n",
      "         -7.5140, -6.6654, -3.8421, -7.5243, -6.5984, -5.5367, -0.8246, -2.5889,\n",
      "         -7.3133, -6.7340, -7.9594, -7.2898, -6.5269, -8.3374, -4.6605, -5.4482,\n",
      "         -7.3946, -8.2005, -7.9628, -6.0347, -7.7938, -7.7111, -6.3044, -7.8707,\n",
      "         -8.0622, -6.1028, -3.2196, -3.6361, -7.6203]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tokenize the inputs\n",
    "inputs = tokenizer(question, story, return_tensors='pt', padding=True)\n",
    "\n",
    "result = model(inputs.input_ids, inputs.attention_mask)\n",
    "\n",
    "print(result)\n",
    "print(result.start_logits)\n",
    "print(result.end_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(141) tensor(143)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ans_start = torch.argmax(result.start_logits)\n",
    "ans_end = torch.argmax(result.end_logits) + 1\n",
    "print(ans_start, ans_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([22823,  2884])\n"
     ]
    }
   ],
   "source": [
    "ans_ids = inputs.input_ids[0][ans_start: ans_end]\n",
    "print(ans_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardboard box\n",
      "cardboard box\n"
     ]
    }
   ],
   "source": [
    "dec_ans = tokenizer.decode(ans_ids, skip_special_tokens=True)\n",
    "print(dec_ans)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure minimum and maximum token length in the answer\n",
    "def ensure_size(input_ids, answer, min_length = 2, max_length = 5):\n",
    "   ans_start = torch.argmax(answer['start_logits'])\n",
    "   ans_end = torch.argmax(answer['end_logits']) + 1\n",
    "   ans_length = ans_end - ans_start\n",
    "   if ans_length < min_length:\n",
    "      ans_end = min(ans_start + min_length, len(input_ids[0]))\n",
    "   elif ans_length > max_length:\n",
    "      ans_end = ans_start + max_length\n",
    "   ans_start = max(0, ans_start)\n",
    "   ans_end = min(len(input_ids[0]), ans_end)\n",
    "   return (ans_start, ans_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Return a minimum of 5 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try this your self\n",
    "\n",
    "context = \"\"\"\n",
    "Dickens wrote A Christmas Carol during a period when the British were exploring and re-evaluating past Christmas traditions, \n",
    "including carols, and newer customs such as cards and Christmas trees. He was influenced by the experiences of his own youth and \n",
    "by the Christmas stories of other authors, including Washington Irving and Douglas Jerrold. Dickens had written three Christmas \n",
    "stories prior to the novella, and was inspired following a visit to the Field Lane Ragged School, one of several establishments for \n",
    "London's street children. The treatment of the poor and the ability of a selfish man to redeem himself by transforming into a more \n",
    "sympathetic character are the key themes of the story. There is discussion among academics as to whether this is a fully secular \n",
    "story or a Christian allegory.\n",
    "\"\"\"\n",
    "\n",
    "question = \"How many stories has Dickens wrote?\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
